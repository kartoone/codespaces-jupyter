{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 18:15:28.395805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 18:15:28.584479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-21 18:15:28.584525: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-21 18:15:31.112148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-21 18:15:31.112387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-21 18:15:31.112407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n",
      "before converting... 5\n",
      "7\n",
      "after converting y... [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 18:15:36.407387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-21 18:15:36.407434: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-21 18:15:36.407455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-782f44): /proc/driver/nvidia/version does not exist\n",
      "2023-02-21 18:15:36.407717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-21 18:15:36.644814: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 11s 2ms/step - loss: 0.3232 - accuracy: 0.9117 - val_loss: 0.1784 - val_accuracy: 0.9472\n",
      "Test loss: 0.17839960753917694\n",
      "Test accuracy: 0.9472000002861023\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras.datasets.mnist as kdm\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# tf.config.set_visible_devices([], 'GPU') # if you have an m1/m2 mac, uncomment this line to run wayyyy faster if you have local install of jupyter. leave commented if you are running on google colab \n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = kdm.load_data()\n",
    "assert x_train.shape == (60000, 28, 28)\n",
    "assert x_test.shape == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "print(\"before converting...\", y_train[0])\n",
    "\n",
    "# reshape\n",
    "img_rows, img_cols = 28, 28\n",
    "# normalize inputs to between 0 and 1\n",
    "import numpy as np\n",
    "x_train = np.true_divide(x_train, 255)\n",
    "x_test = np.true_divide(x_test, 255)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "print(y_test[0])\n",
    "\n",
    "# convert to vector outputs \n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(\"after converting y...\", y_test[0])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  layers.Flatten(input_shape=(28,28)),\n",
    "  layers.Dense(100, activation='sigmoid'),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 18:37:18.577248: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 40s 7ms/step - loss: 0.2579 - accuracy: 0.9239 - val_loss: 0.0757 - val_accuracy: 0.9780\n",
      "Epoch 2/60\n",
      "6000/6000 [==============================] - 37s 6ms/step - loss: 0.0732 - accuracy: 0.9783 - val_loss: 0.0590 - val_accuracy: 0.9822\n",
      "Epoch 3/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.0488 - val_accuracy: 0.9841\n",
      "Epoch 4/60\n",
      "6000/6000 [==============================] - 34s 6ms/step - loss: 0.0412 - accuracy: 0.9879 - val_loss: 0.0490 - val_accuracy: 0.9852\n",
      "Epoch 5/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.0372 - val_accuracy: 0.9882\n",
      "Epoch 6/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0288 - accuracy: 0.9916 - val_loss: 0.0335 - val_accuracy: 0.9889\n",
      "Epoch 7/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.0331 - val_accuracy: 0.9893\n",
      "Epoch 8/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.0311 - val_accuracy: 0.9898\n",
      "Epoch 9/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.0299 - val_accuracy: 0.9895\n",
      "Epoch 10/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.0297 - val_accuracy: 0.9896\n",
      "Epoch 11/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0289 - val_accuracy: 0.9900\n",
      "Epoch 12/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0102 - accuracy: 0.9979 - val_loss: 0.0278 - val_accuracy: 0.9913\n",
      "Epoch 13/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 0.0289 - val_accuracy: 0.9909\n",
      "Epoch 14/60\n",
      "6000/6000 [==============================] - 37s 6ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0275 - val_accuracy: 0.9913\n",
      "Epoch 15/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.0259 - val_accuracy: 0.9914\n",
      "Epoch 16/60\n",
      "6000/6000 [==============================] - 34s 6ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.0254 - val_accuracy: 0.9913\n",
      "Epoch 17/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0271 - val_accuracy: 0.9910\n",
      "Epoch 18/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0262 - val_accuracy: 0.9913\n",
      "Epoch 19/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0274 - val_accuracy: 0.9911\n",
      "Epoch 20/60\n",
      "6000/6000 [==============================] - 37s 6ms/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0272 - val_accuracy: 0.9909\n",
      "Epoch 21/60\n",
      "6000/6000 [==============================] - 36s 6ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
      "Epoch 22/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0264 - val_accuracy: 0.9916\n",
      "Epoch 23/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0273 - val_accuracy: 0.9909\n",
      "Epoch 24/60\n",
      "6000/6000 [==============================] - 34s 6ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0269 - val_accuracy: 0.9909\n",
      "Epoch 25/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0284 - val_accuracy: 0.9912\n",
      "Epoch 26/60\n",
      "6000/6000 [==============================] - 35s 6ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0281 - val_accuracy: 0.9912\n",
      "Epoch 27/60\n",
      "5995/6000 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "  layers.Conv2D(20, kernel_size=(5, 5),\n",
    "     activation='relu',\n",
    "     input_shape=(28, 28, 1)),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Conv2D(40, kernel_size=(5, 5),\n",
    "     activation='relu',\n",
    "     input_shape=(20, 12, 12)),\n",
    "  layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  layers.Flatten(input_shape=(40,4,4)),\n",
    "  layers.Dense(100, activation='relu'),\n",
    "  layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer=SGD(learning_rate=0.03),\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=60,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
